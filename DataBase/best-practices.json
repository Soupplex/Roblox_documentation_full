{
    "title": "best-practices",
    "description": "",
    "content": "{\n    \"title\": \"Best practices when designing MemoryStore data structures\",\n    \"description\": \"Explains how to best design data structures to reduce the chance of experiencing throttling.\",\n    \"content\": \"Depending on the data structure type, MemoryStoreService enforces limits on the memory and number of items in a data structure. All data structures are also constrained by a global per-partition request limit.\\n\\nEach Roblox experience has the Memory Store Observability Dashboard, which includes a set of charts that you can use to monitor memory store usage.\\n\\nSorted maps and queues\\n\\nSorted maps and queues both have limits on the maximum number of items and maximum total memory. Additionally, the items in one of these data structures always reside on a single partition. Every request to one of those data structures is a request to the same partition.\\n\\nWhen a sorted map or queues reaches its item or memory limit, the best course of action is to remove unnecessary items manually or by adding an expiration policy for items. Alternatively, if only the memory limit is causing throttling, you can try to reduce the size of your items by stripping unnecessary information out of your keys and values.\\n\\nIf you need all of your items or are experiencing throttling due to request throughput, the only solution is sharding.\\n\\nSharding\\n\\nSharding is the process of storing a set of related data across multiple data structures. In other words, it means taking an existing, high-throughput data structure and replacing it with multiple, smaller ones that together contain the same set of data as the original.\\n\\nThe key challenge to sharding is finding a way to spread the data across multiple data structures in a way that maintains the same functionality as the original.\\n\\nFor hash maps, although the data structure is already partitioned, sharding is done by spreading the requests among several keys.\\n\\nSharding a sorted map\\n\\nTo shard a sorted map, consider splitting your data into alphabetic subsections with character ranges. For example, assume that you only have keys with the first letter from A-Z, and you believe four sorted maps is sufficient for your current use case and future growth:\\n\\n- The first map can cover A-G, the second H-N, the third O-T, and the fourth U-Z.\\n- To insert or retrieve an item, use the appropriate map based on the item's starting character.\\n\\nUse a helper function to get the correct sorted map from an item key. This way, you don't have to repeat the same block of code for every function call.\\n\\nlua title=\\\"Sharding a Sorted Map\\\"\\n-- Initialize the MemoryStore Service\\nlocal MemoryStoreService = game:GetService(\\\"MemoryStoreService\\\")\\n\\n-- Create your Sorted Map buckets\\nlocal smAtoG = MemoryStoreService:GetSortedMap(\\\"AtoG\\\")\\nlocal smHtoM = MemoryStoreService:GetSortedMap(\\\"HtoM\\\")\\nlocal smNtoT = MemoryStoreService:GetSortedMap(\\\"NtoT\\\")\\nlocal smUtoZ = MemoryStoreService:GetSortedMap(\\\"UtoZ\\\")\\n\\n-- Helper function to retrieve the correct bucket from the Item Key\\nlocal function getSortedMapBucket(itemKey)\\n\\tif (itemKey >= \\\"a\\\" and itemKey < \\\"h\\\") then\\n\\t\\treturn smAtoG\\n\\telseif (itemKey < \\\"n\\\") then\\n\\t\\treturn smHtoM\\n\\telseif (itemKey < \\\"u\\\") then\\n\\t\\treturn smNtoT\\n\\telse\\n\\t\\treturn smUtoZ\\n\\tend\\nend\\n\\n-- Initialize player names with default value of 0\\nfor , player in game:GetService(\\\"Players\\\"):GetPlayers() do\\n\\tlocal bucket = getSortedMapBucket(player)\\n\\tbucket:SetAsync(player, 0, 600)\\nend\\n\\n-- Retrieve a player's value\\nlocal player = \\\"myPlayer\\\"\\nlocal bucket = getSortedMapBucket(player)\\nlocal playerScore = bucket:GetAsync(player)\\nprint(playerScore)\\n\\nSharding a queue\\n\\nSharding a queue is tricker than sharding a sorted map. Although you want to spread the request throughput across multiple queues, adds, reads, and removes only ever occur at the front or back of the queue.\\n\\nOne solution is to use a revolving queue, which means creating multiple queues and rotating between them when you add or read an item:\\n\\n1. Create several queues and add them to an array.\\n1. Create two local pointers. One represents the queue you want to read and remove items from. The other represents the queue you want to add items to:\\n\\n   - For read operations, calculate the number of items you need from each queue, as well as where to move the read pointer to.\\n   - For remove operations, pass the IDs from the read to each queue.\\n   - For add operations, add to the queue at the add pointer and increment the pointer.\\n\\nlua title=\\\"Sharding a Queue\\\"\\n-- Initialize the MemoryStore Service\\nlocal MemoryStoreService = game:GetService(\\\"MemoryStoreService\\\")\\n\\n-- Create your Queues\\nlocal q1 = MemoryStoreService:GetQueue(\\\"q1\\\")\\nlocal q2 = MemoryStoreService:GetQueue(\\\"q2\\\")\\nlocal q3 = MemoryStoreService:GetQueue(\\\"q3\\\")\\nlocal q4 = MemoryStoreService:GetQueue(\\\"q4\\\")\\n\\n-- Put the Queues in an Array\\nlocal queueArr = { q1, q2, q3, q4 }\\n\\n-- Create two pointers representing the indices of the read and add queues\\nlocal readIndex = 1\\nlocal addIndex = 1\\n\\n-- Create a local function that updates the indices appropriately\\nlocal function rotateIndex(index, n)\\n\\treturn (index + n - 1) % 4 + 1\\nend\\n\\n-- Create a local function that reads n items from the queue\\nlocal function readFromQueue(count, allOrNothing, waitTimeout)\\n\\tlocal endIndex = count % 4\\n\\tlocal countPerQueue = count // 4\\n\\tlocal items = {}\\n\\tlocal ids = {}\\n\\n\\t-- loop through each queue\\n\\tfor i = 1, 4, 1 do\\n\\t\\t-- determine if this queue will read an extra item\\n\\t\\tlocal diff = i - readIndex\\n\\t\\tif diff < 0 then\\n\\t\\t\\tdiff += 4\\n\\t\\tend\\n\\n\\t\\tlocal queue = queueArr[i]\\n\\n\\t\\t-- read items from each queue\\n\\t\\t-- +1 items if matches extra read criteria\\n\\t\\tif diff < endIndex then\\n\\t\\t\\titems[i], ids[i] = queue:ReadAsync(countPerQueue + 1, allOrNothing,waitTimeout)\\n\\t\\telse\\n\\t\\t\\titems[i], ids[i] = queue:ReadAsync(countPerQueue, allOrNothing,waitTimeout)\\n\\t\\tend\\n\\tend\\n\\n\\treadIndex = rotateIndex(readIndex, count)\\n\\n\\treturn items, ids\\nend\\n\\n-- Create a local function that removes n items from the queue\\nlocal function removeFromQueue(ids)\\n\\tfor i = 1, 4, 1 do\\n\\t\\tlocal queue = queueArr[readIndex]\\n\\t\\tqueue:RemoveAsync(ids[i])\\n\\tend\\nend\\n\\n-- Create a local function that adds an item to the queue\\nlocal function addToQueue(itemKey, expiration, priority)\\n\\tlocal queue = queueArr[readIndex]\\n\\tqueue:AddAsync(itemKey, expiration, priority)\\n\\taddIndex = rotateIndex(addIndex, 1)\\nend\\n\\n-- Write some code!\\n\\nfor , player in game:GetService(\\\"Players\\\"):GetPlayers() do\\n\\taddToQueue(player, 600, 0)\\nend\\n\\nlocal players, ids = readFromQueue(20, true, -1)\\nremoveFromQueue(ids)\\n\\nHash maps\\n\\nHash maps do not have individual memory or item count limits and are automatically sharded, but you can still encounter throttling if you use them poorly.\\n\\nFor example, consider an experience with a hash map of data, stored as the value of a single key named metadata. If this metadata contains a nested object with information such as place ID, player count, and more, every time the metadata is needed, you have no choice but to call GetAsync(\\\"metadata\\\") and retrieve the entire object. In this case, all requests go to a single key and therefore a single partition.\\n\\nRather than storing all metadata as a single, nested object, the better approach is to store each field as its own key so that the hash map can take advantage of automatic sharding. If you need separation between metadata and the rest of the hash map, add a naming prefix (e.g. metadatausercount rather than just usercount).\\n\\nAdditionally, if one or few keys is being accessed frequently, it's important to shard these calls among a lot of keys. For example, if all experience servers must retrieve a value from one hash map key you may run into partition throttling. To prevent this you can spread those calls among several keys with the same value until partition throttling no longer occurs.\",\n    \"source\": \"best-practices.md\"\n}",
    "source": "best-practices.json"
}